# 基本介绍

不停服维护，顾名思义就是可以在不停服的情况下完成对游戏版本的更新迭代，对玩家来说体验较好，在维护期间不需要登出等待维护结束。据我了解不停服维护大致有这么几种方案。

1. 线上热更，通过代码热更新的方式对业务逻辑进行更新，常用于少量的错误修复，对于大量以及相互之间耦合较深的代码逻辑更新不太适用，风险较高。
    
2. 按照微服务的思想，可以对某部分服务进行不断的扩缩容，逐渐将某个Service的业务逻辑更新到新的版本，一般适用于整个服务器架构严格按照微服务要求进行设计和开发的系统。
    
3. AB服轮转维护，准备两套服务器，在新服上面部署新的代码版本，然后通过轮转流程将玩家逐步从老服转移到新服，最终完成维护。
    

基于我们每次版本的维护都会有大量的功能新增或迭代，以及我们目前的服务器架构中各类服务互相之间的耦合度较高，比较接近于一个完整的服务器整体，所以我们的不停服方案比较适合使用第三种方案。下文讨论的不停服维护方案都指的是这个方案。

# 基本架构

需要部署两套独立但共享数据库的服务器集群，并通过轮转流程实现版本切换，使业务逻辑进行迭代更新，MongoDB和Redis使用的是同一套。另外新老服之间需要进行连通，可以使用类似hub集群之类的方式。在这个结构下，理论上只要修改的范围在logic,router,dbm,cluster之内，都可以通过不停服维护进行更新。

![[Pasted image 20260205092553.png]]

# 优势

玩家体验好，不会有停服维护几个小时进不了游戏的情况，维护期间依然可以进行游戏

维护时间友好，不再依赖低峰时段（如凌晨）

修复线上问题覆盖面广， 如果出现一些难以热更修复的问题可以通过轮转维护进行修复

# 缺点

代码开发复杂度提升

由于引入不停服维护的概念，开发的复杂度会提高，在设计系统时需要考虑在轮转维护下的情况，当然在轮转维护的框架设计合理的情况下，这部分的成本是可控的。[Service接入轮转维护的设计规范](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.jj7nqvtmsso8)  [玩家Component接入轮转维护的方案](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.7avk78m86crx)

扫档限制

走轮转维护的话比较难进行扫档操作。当然目前对于玩家脏数据有 [fix_data修复玩家数据设计文档](https://docs.corp.kuaishou.com/k/home/VSySLoKp-SCY/fcADzbvYtvLrClVgP8rgxhMjG)机制（时机在玩家上线时）进行修复。也可以考虑在服务器外增加一种动态扫档的机制，在玩家不在线时对数据库数据进行扫档修复。

机器费用提高

轮转维护意味着需要两套服务器架构，最简单的方式就是完全部署两套相同的服务器，各自独占设备。当然如果要省机器费用的话也可以考虑将新服老服部署在相同的机器上，因为理论上机器在没有玩家在线的情况下对于性能的占用是比较低的，在轮转过程中同一个玩家也只会在一个服务器内（新服or老服）总的在线人数并不会增加。

# 方案介绍

## 大致流程

在轮转期间（即新老集群并行运行阶段），老服先进入功能屏蔽状态，待新服完成数据加载后，引导玩家重新登录至新服。（具体见下文的流转流程）新老服在数据层面需要尽可能的实现互斥。

## 轮转维护流程图

![[Pasted image 20260205092615.png]]

轮转维护大致可以分为五个阶段

## 阶段1

- 新服启动但是但禁用数据持久化 ，老服无任何影响。[如何关闭数据持久化](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.kkcxh7bofk6i)
    
- qa在新服进行相关测试
    

## 阶段2

- 新服测试完毕，可以开始进行轮转维护，通知老服开始维护
    
- 老服屏蔽大部分Service功能，此时会对玩家产生影响，发现部分功能不可用，例如无法加好友，无法创建公会，无法新开副本等，已经在一些副本玩法中的不影响。对于无法屏蔽的服务进行消息的缓存。
    
- 然后老服大部分Service进行存盘，全部完成存盘后通知新服，新服会从数据库中加载数据
    
- 这个阶段和后面的阶段3要尽量把时间缩短，因为这个阶段会出现玩家在老服功能受限，并且还不能登录新服的情况。
    

## 阶段3

- 新服开始读取数据，此时允许新服进行数据持久化。
    
- 新服读取数据完成后，可以对外服务。
    
- 通知老服新服已经ready，之前缓存消息的一些Service可以开始进行消息转发。
    
- 新服ready后修改客户端指向，玩家的新登录会进入新服。
    

## 阶段4

- 部分玩家依然滞留在老服，此时老服的功能会受限，一些获取类的功能可以考虑继续开放，新开副本，以及一些会修改非玩家数据的服务需要屏蔽。
    
- 少数无法完全屏蔽的Service例如排行榜继续进行消息的转发操作。
    

## 阶段5

- 在阶段4等待一段时间后（可以以时间较长的一类副本玩法作为时间阈值）保证基本所有玩家都不在进行一些玩法，而只是待在主城还未下线，进行强制下线操作。
    
- 确保数据落地后关闭旧服节点，轮转流程结束。
    

# 具体实现方案

## Service接入轮转系统的设计规范

### step1

判断Service是否是必须进行屏蔽，轮转需要达到的一个最终目标就是让老服上不再存在进行中的副本玩法，此时对于副本创建类的功能必须屏蔽，即使这个Service可以支持新老服同时开启。

对于需要屏蔽的Service，需要实现以下接口

```
function WorldService:onMTStage2Start()
  -- set block flag
  -- stop timers
  -- start db save, block new db save request
  -- after save, inform MTController finish stage2 process
 end
```

[如何进行批量的轮转阶段功能屏蔽（老服）](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.v5o5xgunr0kk)

### step2

对于不是必须要屏蔽的Service，有一些是支持服务器相关功能的Service，这些程序可以自主判断是否需要在轮转阶段支持，另外需要考虑Service是否会被其他Service依赖，如果所有依赖它的Service都可以屏蔽，那它也可以屏蔽，如果不是则需要进行某种程度的支持。

有一些是和需求相关的Service则需要和策划沟通确认在轮转期间是否需要支持。一般来说即使是走屏蔽，也只是在2,3阶段会出现老服不可用，新服未开启的情况，这个时间段较短（应该小于5分钟），在进入4阶段后可以引导玩家进入新服就可以继续完整的体验游戏的所有功能，所以建议优先选择屏蔽老服功能以降低轮转维护的复杂度。

### step3

对于需要在轮转阶段支持的Service，可以分为以下几类

Service没有任何db存盘数据，此时可以认为Service在重启后不需要恢复数据，也不存在同时读取和修改同一份的数据的情况，一般来说不需要特别处理，新老服分别启动Service对自己的服进行功能服务即可，例如OnlineService，RouterService

Service有db存盘数据，但是db数据是独立的，此时Service的db写数据是天然支持轮转维护的，对于数据的读取，需要判断读取的时机是否有变化，而这个时机的变化是否会影响最终的业务表现，例如一些写db之后通知在线玩家读取数据库之类的操作，如果玩家在新服可能通知不到，按照离线玩家进行处理，那么后续玩家重新登录的时候再触发是否也没有问题。如果对时机比较敏感，则需要支持在轮转阶段，Service可以发送消息到另外服上玩家的机制（新服Service->老服玩家，老服Service->新服玩家）[新老服rpc互通](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.jgff5e999mpd)

Service有db存盘数据，并且存在同时读，同时写同一份数据的场景。此时可以考虑是否可以将数据库结构改为相互独立。如果不行，则可以再将情况分为2类

一类为数据的实时性要求不高，可以接受在一段时间内拿不到最新的数据，只要求最终的数据完整性，例如RankService，此时可以考虑一种缓存+转发的方案，在2,3阶段屏蔽老服存盘操作，并缓存后续的请求，在4阶段开始后，发送之前缓存的请求并持续转发后续的请求。

```
function WorldService:onMTStage2Start()
  -- set cache flag
  -- start db save, block new db save request
  -- after save, inform MTController finish stage2 process
 end
```

```
function WorldService:onMTStage4Start()
  -- send cached msg
  -- set transfer flag
 end
```

一类对于数据的实时性要求较高，需要在发生请求之后立刻能获取到对应的数据。对于这种情况有两种对应的方案

方案1：

阶段2开始后老服屏蔽数据库操作，缓存请求的同时继续对内存数据进行操作（和原来的逻辑一样，只是不存盘）在阶段4开始后，将缓存数据转发到新服Service（相当于2,3阶段的请求新老服都执行了一遍，只是老服没有存盘）之后，不再继续缓存+内存数据的操作，转为仅转发到新服的操作，统一由新服Service进行处理。此时需要支持新服Service与老服玩家的rpc互通。[新老服rpc互通](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.jgff5e999mpd) 另外此时需要关注在老服屏蔽db存盘的情况下接口是否满足可重入标准，例如只是在Service修改内存数据就没关系，如果会触发一些发奖逻辑，则需要额外加一些可重入的保护。（例如在玩家层记录是否已经领取过奖励的flag）

```
function WorldService:onMTStage2Start()
  -- set cacheAndContinue flag
  -- start db save, block new db save request
  -- after save, inform MTController finish stage2 process
 end
```

```
function WorldService:onMTStage4Start()
  -- send cached msg
  -- set transfer flag
 end
```

方案2：

方案1中提到继续在老服继续做逻辑主要是考虑到2,3阶段可能仍然有几分钟的时间（需要所有Service完成存盘已经新服阶段的重启）。那么另外一个方向就是将这个时间降到最低，此时需要单独支持某个Service可以单独进行阶段2到阶段4，在这个Service自己存盘结束后通知新服并启动。此时这个Service可以快速的完成切换，直接进入阶段4后就按照转发加 [新老服rpc互通](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.jgff5e999mpd) 来进行后续的处理。

## 玩家Component接入轮转维护的方案

### step1

判断该Component下的相关功能是否限定在玩家自己内部，不包含一些外部的依赖。如果仅玩家自己的一些行为，天然支持轮转维护，不需要做额外处理。[玩家新老服登录互斥](https://docs.corp.kuaishou.com/d/home/fcAA2f9NjlOd09AkhF8Ao6z0h#section=h.p6kserkkr01a)

### step2

该Component与Service会有交互，此时可以参考Service最终的支持级别，Component也保持一样即可，Service屏蔽则在Component也屏蔽，Service支持则在Component不需要额外做特别处理，继续与Service进行交互。

### step3

如果Component里面有直接对db的操作，并通过db来进行数据的共享和同步，则参考上面Service里对于db的处理。

## 如何进行批量的轮转阶段功能屏蔽（老服）

1. Service的功能大部分是由CallService触发的，最终会转化为Service的rpc，可以在相关文件最后增加统一的注册，增加一个判断的装饰函数，对于rpc的请求统一进行限制（可以把某个xml下定义的请求rpc都默认屏蔽掉）。
    
2. 对于Component下的函数，如果整个Component相关的功能也会屏蔽，也一样可以在相关文件最后增加统一的注册，增加一个判断的装饰函数，对于客户端上行的rpc统一进行限制（可以把某个xml下定义的客户端rpc都默认屏蔽掉）。
    
3. 对于Timer，Service上的Timer可以参考上面的Service的轮转维护实现规范，Component上的Timer是玩家级别的，一般可以和Component本身是否屏蔽保持一致。
    
4. 增加通用判断函数，其他零散的点需要单独增加轮转判断逻辑。
    

## 如何判断新老服

首先在配置中增加AB服配置，A服里面配置target服为B服，B服则配置为A服，有这个配置的服务器在启动时会去对应的另一个服进行查询，如果另一个服没有启动则使用默认起服流程，正常起服，如果另一个服启动了，则把自己当做新服，而另一个服则当做老服处理。

另外可以支持GM指令进行修改，在自动判断的流程出现错误时可以进行手动设置。

## 玩家新老服登录互斥

玩家数据的互斥通过限制玩家同时在新老服登录完成。在轮转过程中，玩家登录到新服时，会触发去老服踢自己下线的操作。新服登录时会发送rpc去老服踢自己下线，收到后继续进行登录流程，如果超时没有收到回复则登录失败。

## 如何关闭数据持久化

有两种方式

1. 在logic脚本层的通用入口进行屏蔽
    
2. 在dbm层进行屏蔽
    

目前会倾向于使用第一种，因为脚本层热更相对容易，如果出现问题也相对容易修复，另外对于一些业务逻辑进行特殊处理也更灵活（对于一些不污染线上数据的表可以允许写入，例如邮件，这里的判断标准是数据是否是限定在玩家自己内部的，还是更偏向公共的会被其他玩家或者玩法看到或使用的。默认可以在阶段1把新服的所有表写入关闭，然后根据设计的冒烟case分析哪些表可以允许写入，并确认后续的清理逻辑，如果需要清理的话）。

屏蔽持久化后返回给调用方的结果可以是succ，这样只依赖内存的逻辑依然可以测试。

另外针对新服是否会存在写数据库出现问题而没法在阶段1测试时发现的情况，可以设计几个简单的场景进行一些数据的写入，单独测试数据库的连通性，避免新服上没法写库但在测试时也没有发现，如果冒烟测试中包含了会写库的case就不需要了。

另外可以在阶段1对新服的dbmgr进行大盘监控，应该基本没有db的写入操作。

## 控制轮转进程的推进

主要由流水线人工推进，例如进入阶段2，就通过gm往新老服同时设置轮转维护状态。有一些状态也可以自动推进，可以在cluster里加一些逻辑，例如阶段2所有老服Service存盘结束后，打印一个日志，然后在流水线中可以发现，开始推进阶段3，新服Service开始从db中加载数据。

## 新老服rpc互通

这里需要考虑两点

### 新老服链路

新老服在架构比较像是2个服，目前还不确定跨服之间服与服直接的通信方式，但应该是类似的，可以考虑复用

### rpc向下兼容

另外新老服通信有一点与跨服不同的是代码版本会有所不同，此时需要考虑rpc的兼容问题。

#### CallService

老服Service <-> 新服Service。此时需要新服兼容老版本的rpc，如果rpc结构变化需要新服需要进行转化，同时在回复rpc时也要转化成老rpc的格式。这里可以考虑是否在引擎层的callLuaEntity和callLuaEntityWithCallback触发到脚本层时加一层前置的通用处理，这样可以在通用的地方进行协议的转化。不然在修改协议时就需要在具体的Service层定义规范，不能直接改老协议，而是需要新增协议，新服代码类似这样。

```
function OnlineService:SOnMsgUploadOnlineInfo(avatarMb)
  ...
  local ret1, ret2 = self:SOnMsgUploadOnlineInfo_new(avatarMb, 1) -- 调用时增加一个默认值
  return ret1	-- 这里也要兼容老版本，如果cb的返回值也改了的话
end

function OnlineService:SOnMsgUploadOnlineInfo_new(avatarMb, val)
  ...
end
```

老服Avatar<->新服Service。和上面类似，一样需要进行rpc的兼容。另外Service中可能会存储AvatarID或者mb，后续进行相关的调用。此时需要额外支持通过AvatarID对玩家的调用以及通过mb对于玩家跨新老服的调用。

#### 通过AvatarID

可以考虑玩家在登录时在Redis中记录自己登录的服务器id，在新服的RouterService中，如果在轮转流程中，且未通过AvatarID找到mb，判断Redis中玩家是否在老服登录，如果时则转发到老服的RouterService进行处理

#### 通过mb

这个可能需要引擎底层支持，在mb中增加服务器id相关的信息，可以进行类似跨服的转发，同样依然需要考虑rpc版本兼容的问题

# 风险&可能的解决方案

## Service同时存盘的性能压力

在阶段2开始时会出现所有Service进行存盘的操作，需要梳理压测一遍service需要存盘的量级，可以结合压测看是否需要做一些性能上的削峰处理，例如分批落地。

## 新服登录时没有收到老服踢掉自己的成功回调

上面玩家互斥环节也提到了，期望收到回复正常进行登录，虽然可以通过term去保证老Avatar没法落地数据，但这个老Avatar依然可以在老服进行一些行为，风险较大。

## 轮转流程中出错后如何恢复

### 阶段1

1. 新服出错，此时还未开始轮转，如果新服出现问题比较好处理，基本可以比较自由的操作，重启，更新代码都可以。
    
2. 老服出错，和常规问题一样，热更
    

### 阶段2，3

1. 新服出错，此时的处理策略为恢复老服，因为客户端的指向仍然为老服，而新服也没有ready，停止轮转，将老服屏蔽的功能重新开放（把轮转切换到阶段1）。待问题排查处理结束后再进行轮转维护。
    
2. 老服出错，和常规问题一样，热更
    

### 阶段4

1. 新服出错，和常规问题一样，热更
    
2. 老服出错则优先考虑尽快使用新服，可以根据问题的严重程度判断是否要加速阶段4，踢掉老服玩家，将玩家都指引到新服。或者老服人数较多没法踢则是否有一些快速的热更手段。
    

### 阶段5

此时是在老服踢玩家下线的流程了，一般不会有影响较大的问题出现，与轮转流程也不会有太大的关联了，按照正常的问题去处理就行了。可能会出现踢下线失败，或者数据落地的问题，但其实和轮转关系不大，常规的登出失败也是一样的，按照登出失败进行对应处理。

## 被非玩家来源修改玩家相关数据如何处理

轮转过程中不会直接踢玩家下线，也就是说老服依然需要支持玩家的数据持久化，而玩家数据的互斥主要依赖于玩家entity的互斥（新老服只能在一处登录），但是也可能有少部分需求会出现非玩家来源修改玩家属性的情况。此时即使玩家entity互斥了，依然有可能会出现新老服都在修改玩家属性的情况。此时需要分析这些数据是否本身就支持并行修改，例如新服修改db中的数据后，老服玩家如果存盘的话，会不会把数据刷掉。此类数据需要单独梳理不过预计应该非常少。（帮会数据，邮件，umsg等）

这里建议的做法是对于在线的玩家可以发送到玩家对象进行修改，不在线的玩家在登录时去拉取更新这些"外部"数据，例如好友申请，帮会数据等，现在也是这么做的。不建议绕开玩家对象直接修改玩家Entity上的db数据（一般也不会），这样的话玩家登录新服后数据最终的来源会是外部的这些db表，而这些db表可以通过上面提到的互斥原则保证在轮转过程中数据的一致性。

# 一些拓展思考

## 是否可以自动帮玩家重新登录，以切到新服

对于那些没有在玩法副本中的玩家，是否也可以考虑直接进行一个下线重新登录的流程（在修改客户端指向之后），然后在前端可以做一些表现，让玩家没有明显感受的情况下就登录到新服了。这里需要和策划确认是否可以这么做。

## 是否可以提先屏蔽创建副本

目前的方案中，玩家在老服受限并无法登录新服的时间在阶段2和阶段3，这段时间应该在几分钟之内。但是后续的阶段4会长一些（等待进行中的重要副本结束），那么还有另外一种方案，在阶段2就限制创建副本，然后等待一段时间后（等待进行中的重要副本结束）此时再进行轮转，此时已经没有进行中的重要副本了，可以更快速更彻底的直接把老服玩家切到新服，例如客户端指向变了之后，老服推送一个请求到在线客户端直接让客户端重登进入新服。这样对于玩家在新老服登录的顶号，RankService的转发这些新老服共存的支持就不是很必要了，轮转的复杂度可以降低。当然对玩家的影响会大一些，会有比较长的一段时间没法新创副本。

![[Pasted image 20260205092641.png]]