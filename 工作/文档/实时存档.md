## 概述

传统的网游服务器，为了缓解db的压力，一般会让每个entity间隔一段较长的时间（比如15分钟）才进行一次全量的存盘操作。这个较大的时间间隔带来了一个问题，就是回档。如果玩家在这15分钟内获得了好东西或者消费了rmb，在还没存盘之前服务器挂了，玩家是会闹翻天的。我们以前一般会在玩家获得了贵重物品或者进行了重要操作之后，主动进行一次存盘，这个就需要玩法重度参与存盘的策略，属于没有办法的办法。

减少存盘的时间间隔，db受不了，增加存盘的时间间隔，玩家受不了。为了解决这个问题，大家开始纷纷研究“实时存盘”功能。据我所了解的，大致有下面几种：

1. 存盘时间有一定的间隔，每次存盘属性修改都会记录一条修改log。游戏进程非正常退出后，重启进程时会跑一个自动扫log来修正存盘数据的脚本，让存盘数据能追到游戏进程刚退前的状态。就像数据库的binlog一样。
    
2. 每次修改存盘属性都执行一个修改这个属性的db操作，可谓“真•实时存盘”。带给db的压力可想而知。
    
3. 在dbmgr存一份entity存盘属性的快照，在entity的存盘属性进行修改时，会发一个rpc给dbmgr增量同步这个属性，让快照保持和entity一致。当游戏进程挂了时，db会用这个快照进行存盘；当dbmgr挂了时，游戏进程可以再选个新的dbmgr，在上面重建entity的快照。然后定期把dbmgr的缓存存盘即可。这个方案的优点是开销小，有个小缺点是万一游戏进程和dbmgr同时挂了，entity数据就回档了。所以我们启用实时存盘后，引擎会自动保证logic和dbmgr在不同的机器上。
    

我们引擎采用的是第3种方案。

## 启用实时存盘的相关改动和接口

1. 新增配置enable_realtime_save(此配置作用于logic和dbmgr)，需要设置为true，才能用上实时存盘功能。还需要在createEntityFromDB时realtimeSave参数为true才能开启具体entity的实时存盘功能（详见下一条说明）。新增配置log_realtime_save(此配置作用于logic和dbmgr)，默认false。刚接入实时存盘时可以打开本开关，在dbmgr和logic都会留下[REALTIME_SAVE]打头的实时存盘相关log。开启实时存盘功能后，对于lua logic，所有存盘属性会变成和own_client/all_clients一样的需要同步的属性(属性写性能下降)，这些属性在每次修改后都会增量同步给dbmgr，会有一定的性能开销，可以考虑用引擎原本的SyncInterval功能来降低会频繁修改的属性的同步频率。(SyncInterval目前只以一级属性为单位同步，也就是即使你只改了一个一级属性的n级子属性，也需要同步整个一级属性。所以使用此功能时需要权衡利弊)
    
2. Entity.createEntityFromDB参数修改，增加了realtimeSave参数，默认false。
    

lua: Entity:createEntityFromDB(dbName, colName, entityType, entityID, canMigrate,   

      realtimeSave, callback)

python: Entity.createEntityFromDB(dbName, colName, entityType, entityID, timeout,  

     initData, realtimeSave, cb, notExistCB)

3. 如果是新建的entity，调用self.enableRealtimeSave(db_name, collection_name)则可以让这个entity启用实时存盘功能。Entity.isRealtimeSave()返回entity当前是否开启了实时存盘功能。
    
4. 调用self.disableRealtimeSave()接口可以取消实时存盘功能，恢复传统存盘模式。
    
5. 开启实时存盘后，会在每一步关键操作都进行相关校验，如果出现了错误，会立即退出实时存盘模式，并且调用Entity:onAbortRealtimeSave函数通知脚本。脚本在收到这个回调之后，应该做一些恢复传统存盘的逻辑(比如调整存盘间隔或者是立即再存一次盘)，并且检查log看看是啥原因导致的。
    
6. 开启实时存盘后，若要主动存盘，还是调用saveTo/saveAndShutdown接口。不过行为已有所不同，引擎只会把meta信息(_id, _entity_type等字段)打包(不包含entity属性信息)发给dbmgr，然后和dbmgr中的属性cache结合来生成存盘数据进行存盘。所以在logic上的开销会比传统存盘小很多。由于开启实时存盘之后dbmgr和logic互为备份，只要不同时挂数据就不会丢，但是不建议把存盘间隔改得太大，毕竟只要数据没写到磁盘上，就有丢失的风险。
    
7. 新增配置realtime_save_choose_new_dbmgr_max_delay(作用于logic)，默认5.0秒。在dbmgr挂了之后，logic会收到通知，绑定在这个dbmgr的entity需要重新序列化数据，发给新绑定的dbmgr。由于担心一瞬间太多entity需要做这个序列化操作会使logic卡顿，会从0~realtime_save_choose_new_dbmgr_max_delay之间random一个时间，在这个时间之后再进行此操作。这个值也不能设太大，因为如果在此之前logic也挂了，那就真的gg了。
    
8. 新增配置enable_realtime_save_cache(作用于dbmgr)，默认true。开启之后dbmgr上每份entity cache，会存储一份以一级属性为单位的序列化好的cache。每次存盘序列化，只需要重新序列化脏数据（以一级属性为单位），提升性能。(由于存储的是序列化好的数据，内存开销不会太大，盲猜只有entity_cache本身的1/2以下，所以已经改为默认开启)
    
9. 新增配置realtime_save_skip_save_if_no_prop_change(作用于dbmgr)，默认false。设为true之后，当两次存盘之间没有存盘属性的修改，则跳过第二次存盘。
    
10. 新增配置realtime_save_sync_props_batch_size(作用于logic)，默认100。意思是每个entity在一个tick内积累了100次同步属性的请求之后才把这些请求合批打包发送给dbmgr进行处理。在每个tick结束后(大概1秒10次)、发起存盘之前和迁移之前，也会把当前积累的属性同步请求发送给dbmgr进行处理。这个值太小了影响性能，太大了可能导致卡顿甚至一个包超大，默认100就蛮好。
    
11. 增量存盘功能 新增配置realtime_save_incremental_update_threshold(作用于dbmgr)，默认0。设为>0的值之后启用增量更新功能，当发起存盘请求时，如果所有脏属性序列化后大小/全属性序列化后大小 < 本配置值，则本次存盘启用增量更新。即从replace_one改为update_one，$set修改的属性，$unset设为了default值的属性。开启本功能要求enable_realtime_save=true, enable_realtime_save_cache=true。增量更新和enable_realtime_save_cache一样，都是以一级属性为最小单位的。即如果一个巨复杂的属性，只要修改了它的任何一个子属性，增量存盘时都要$set这整个一级属性。启用此功能有望较大降低mongodb的负载，最佳的阈值需要项目结合实际压测得出。
    
12. 新增配置realtime_save_writedb_on_switch_dbmgr(作用于logic)，默认false。当一个entity迁移到一个新的logic时，如果发现这个logic和它的实时存盘dbmgr在同一台机器上，就会尝试重新找一个不在这台机器上的dbmgr来作为实时存盘dbmgr（目的是避免这台机器挂了的时候，logic和dbmgr一起挂了导致数据丢失）。如果找到了新的dbmgr，就需要删掉旧的dbmgr上的cache，然后在新的dbmgr上创建cache。万一在这个过程中logic跪了（概率极小），entity就会被回档了。所以增加了这个开关，在删旧cache之前会进行一次存盘操作，这样就避免了这个万一了。建议配合上面的增量存盘功能开启，以减小存盘带来的开销。
    

  

## 实时存盘工作流程

1. 通过Entity.createEntityFromDB(...realtimeSave=true...)加载已存盘的entity，dbmgr在加载此entity时，会同时在dbmgr创建好这个entity的cache。或者新建entity之后调用Entity.enableRealtimeSave(db_name, col_name)，也会通知dbmgr创建好cache。同时这个entity会记录下这个dbmgr的pid，也就是绑定，在迁移时也会保持这个绑定关系不变。后面这个entity都只会通过这个绑定了的dbmgr进行存盘。
    
2. 脚本在修改了任何存盘属性之后，都会发送一个rpc给dbmgr去增量同步cache，这个rpc里还包含了自增之后的term_index，这个term_index以前是用来防止万一有先后两次的存盘操作，保证不会用了旧数据去覆盖新数据的。实时存盘也利用这个term_index来保证所有增量同步都不会漏了，具体就是每次dbmgr收到包含term_index的rpc时，严格判断新的term_index只比本地的大1。
    
3. 开启实时存盘后，dbmgr本身不会主动去把cache存盘，只有脚本调用了saveTo/saveAndShutdown接口时，才会进行存盘操作。但是如果entity所在logic跪了，dbmgr会把在这个logic上的所有entity，用它们的cache进行存盘操作。为了实现这一点，entity在每次一迁移完毕之后，都会把新的logic_pid发给它绑定的dbmgr。
    
4. 开启实时存盘后，如果没有指定prefer_dbmgr配置，则在logic随机选取dbmgr时会优先选择非本机的dbmgr。此举是为了避免机器挂了的时候logic和dbmgr被一锅端了而导致entity数据丢失。
    
5. 为了避免同一个entity所在的logic和dbmgr因为服务器挂了而导致丢数据，entity在迁移后，引擎如果发现当前logic和entity实时存盘所用的dbmgr在同一台机，就会把这个entity的实时存盘dbmgr换一个。此操作需要重新序列化存盘属性并且发给新的dbmgr重建cache，有一定的开销。
    
6. 如果重复加载一个已经加载过的entity，行为保持和非实时存盘基本一致。即新加载的entity有效，旧加载的entity由于term已经比db中的旧了，在存盘时会报错，并且回调onEntityInvalid。细节上有点不同：
    

7) 当新旧entity的dbmgr是同一个时(新旧entity的cache都指向了dbmgr中的新cache)，旧

entity修改存盘属性同步给dbmgr时，由于term比新cache中的term要旧了，会触发

退出实时存盘并回调onAbortRealtimeSave。存盘时会报onEntityInvalid。

2) 当新旧entity的dbmgr不同时(新旧entity在不同dbmgr上有各自的cache)，旧entity修改存盘

属性不会触发退出实时存盘。存盘时会报onEntityInvalid。

  

## 附带福利：AOI属性cache优化

基于实时存盘的那套属性和同步机制，我们优化了AOI属性cache功能。

use_aoi_prop_cache=true即可以开启此功能。

未开启此功能时，每次entity进入别人的aoi，都需要把all_clients属性序列化发送给别人的客户端。如果进入100人的视野，就需要在主线程序列化100次。开启之后，会在aoi线程创建一份entity cache，每次all_clients属性修改时就增量同步给这个cache，进入别人视野时只需要在aoi线程从cache序列化(cache拥有一级属性级别的子cache，某个子属性修改了，只需要重新序列化这个子属性所属的一级属性)再发送给别人客户端就好，不会阻塞主线程。log_aoi_prop_cache=true则可以打开本功能的详细log，打开之后，会打印[AOI_PROP_CACHE]开头的相关log用于调试。