## 5
#PostgreSQL
https://openai.com/zh-Hans-CN/index/scaling-postgresql/
这里理解
PostgreSQL的写是主库单点的，而读是分布式的
这个是数据库本身也是比较适合读密集型的服务，不适合写密集型
而Chatgpt里面一些用户聊天的元数据
例如：
- conversation_id
- user_id
- 会话状态
- 最近一条消息时间
- 权限 / 可见性
- 是否被归档、删除
- 审计 / 合规标记
这类数据的特征：
- 数据行小
- 读频率极高
- 写相对可控
- 需要事务 / 约束 / 演进 schema
很可能是由PostgreSQL承载的因为这是它擅长的。
而聊天的具体内容很可能是由Azure Cosmos DB负责存储的
这是比较典型的NoSQL，擅长分布式写，对于大量的写入支持较好

然后一些优化的思路
## 单主 + 多读副本架构（扩展读取能力）

为了扩展 PostgreSQL 的**读性能**，OpenAI：
- 使用了 **一个主库（Primary）** 处理写入操作；
- 部署了 **∼50 个只读副本**（Read Replicas），分布在多个地理区域；
- 所有读请求尽可能路由到这些副本，从而分散负载。

这样做极大提升了对于**全球大量用户并发读取**的支持能力。

## 控制主库请求

要让 PostgreSQL 在这个规模下稳定运行，他们做了很多传统数据库不一定会做的优化和实践：
### ✅ 减轻主库压力

- 把大量读请求送到只读副本；
- 对写入操作进行限频，针对峰值可以延迟处理，削峰
- 限制多表联合查询

### ✅ 迁移写密集型工作负载

对于写入压力较大的，可分片的数据，**迁移到了分片系统（如 Azure Cosmos DB）**。  
这意味着 PostgreSQL 不再承担所有写入任务。

## 连接管理与缓存优化

为了使 PostgreSQL 在高并发下稳定运行，他们还：

- 使用 **PgBouncer 连接池** 来减少数据库连接压力（高效复用连接）；
- 使用缓存（中间层）来减少对数据库的直接访问；
- 防止缓存穿透时大量请求打到数据库。具体一点，当多个请求同时未命中同一缓存键时，只有一个请求能获得锁，进而检索数据并回填缓存，其他所有请求则等待缓存更新，而非同时涌向数据库

这些措施帮助 PostgreSQL **承受高并发访问**。

## 读副本扩展机制改进

随着副本数量增加，主库复制压力也会增长。OpenAI 与 Azure PostgreSQL 一起测试 **级联复制（cascading replication）**
我理解就是分级，100个副本一级的话，那就是每次同步100份数据到副本，分两级每级10个的话
主库只同步10条数据，下面的次级副本每个也是一次同步10条数据到底层副本
![[Pasted image 20260205102827.png]]